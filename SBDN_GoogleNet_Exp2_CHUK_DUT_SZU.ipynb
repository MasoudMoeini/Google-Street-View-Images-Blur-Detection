{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPyYXcU31A7wj78Lppte5xK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasoudMoeini/Google-Street-View-Images-Blur-Detection/blob/main/SBDN_GoogleNet_Exp2_CHUK_DUT_SZU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK1xxTagBKXt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
        "from keras.layers import Concatenate\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq BlurDatasetImage.zip"
      ],
      "metadata": {
        "id": "KYpx1LlHBkgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq BlurDatasetGT.zip"
      ],
      "metadata": {
        "id": "LcGnfj2xBlGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import *\n",
        "images_folder= \"image/*\"\n",
        "labels_folder = \"gt/\"\n",
        "def data_preprocessing(images_folder,labels_folder):\n",
        "  total_img = []\n",
        "  labels = []\n",
        "  files = glob.glob (images_folder)\n",
        "  for myFile in files:\n",
        "    image_name=os.path.split(myFile)[1]\n",
        "    if image_name[:12]=='out_of_focus':\n",
        "    # image resize\n",
        "      img = Image.open(myFile)\n",
        "      img = img.resize((224, 224))\n",
        "      img = np.asarray(img)\n",
        "      total_img.append(img)\n",
        "      #Gt \n",
        "      image_name=image_name[:-3]\n",
        "      image_name=image_name+'png'\n",
        "      label = Image.open(labels_folder+image_name)\n",
        "      label = label.resize((224, 224))\n",
        "      label = np.asarray(label)\n",
        "      if (label.shape!=(224,224)):\n",
        "        label=label[:,:,0]\n",
        "      labels.append(label)\n",
        "  total_img = np.array(total_img)\n",
        "  labels = np.asarray(labels)\n",
        "  label= np.reshape(labels,[labels.shape[0],labels.shape[1],labels.shape[2]])\n",
        "  total_img= np.reshape(total_img,[total_img.shape[0],total_img.shape[1],total_img.shape[2],total_img.shape[3]])\n",
        "  return labels,total_img"
      ],
      "metadata": {
        "id": "J2rbE_ofBnyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUK_labels,CHUK_images=data_preprocessing(images_folder,labels_folder)"
      ],
      "metadata": {
        "id": "_Fip3hHYBxnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUK_images.shape"
      ],
      "metadata": {
        "id": "-F9mlXwbB3-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHUK_labels.shape"
      ],
      "metadata": {
        "id": "ax3YiL0nB61e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inception(x, filters):\n",
        "    # 1x1\n",
        "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "\n",
        "    # 1x1->3x3\n",
        "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
        "    \n",
        "    # 1x1->5x5\n",
        "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
        "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
        "\n",
        "    # 3x3->1x1\n",
        "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
        "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
        "\n",
        "    return Concatenate(axis=-1)([path1,path2,path3,path4])"
      ],
      "metadata": {
        "id": "p4n05crBCWmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ident_auxiliary(x,name=None):\n",
        "  dec3 = layers.Conv2DTranspose(256, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)#28*28*512\n",
        "  dec4 = layers.Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec3)#56*56*128\n",
        "  dec5 = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec4)#112*112*32\n",
        "  dec6 = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec5)#224*224*3\n",
        "  dec7 = layers.Conv2DTranspose(3, (3, 3), strides=1, activation=\"relu\",padding=\"same\")(dec6)#224*224*1\n",
        "  dec8 = layers.Conv2DTranspose(1, (3, 3), strides=1, activation=\"relu\",padding=\"same\")(dec7)#224*224*1\n",
        "  #FusionNetwork\n",
        "  Upsam_Deep = layers.Conv2DTranspose(128, (3, 3), strides=8, activation=\"relu\", padding=\"same\")(dec3)\n",
        "  Upsam_Shallow1=layers.Conv2DTranspose(16, (3, 3), strides=4, activation=\"relu\", padding=\"same\")(dec4)\n",
        "  Upsam_Shallow2=layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec5)\n",
        "  concatted_Shallow = tf.keras.layers.Concatenate()([Upsam_Deep,Upsam_Shallow1,Upsam_Shallow2,dec6])\n",
        "  result_concatted_Shallow= layers.Conv2D(1, (1, 1), strides=1, activation=\"relu\", padding=\"same\")(concatted_Shallow) #224*224*1\n",
        "  #Concatenate all results\n",
        "  concatted_all = tf.keras.layers.Concatenate()([dec7,result_concatted_Shallow])\n",
        "  Axilary_final_output= layers.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\", padding=\"same\",kernel_regularizer=regularizers.L2(l2=0.005),\n",
        "      bias_regularizer=regularizers.L2(l2=0.0005),name=name)(concatted_all) #224*224*1\n",
        "  return Axilary_final_output"
      ],
      "metadata": {
        "id": "Ba7G-gxACco0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identifier(x,name=None):\n",
        "  dec2 = layers.Conv2DTranspose(512, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x) #14*14*512\n",
        "  dec3 = layers.Conv2DTranspose(256, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec2)#28*28*256\n",
        "  dec4 = layers.Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec3)#56*56*128\n",
        "  dec5 = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec4)#112*112*32\n",
        "  dec6 = layers.Conv2DTranspose(3, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec5)#224*224*3\n",
        "  dec7 = layers.Conv2DTranspose(3, (3, 3), strides=1, activation=\"relu\",padding=\"same\")(dec6)#224*224*1\n",
        "  dec8 = layers.Conv2DTranspose(1, (3, 3), strides=1, activation=\"relu\",padding=\"same\")(dec7)#224*224*1\n",
        "  #FusionNetwork1\n",
        "  Upsam_Deep1 = layers.Conv2DTranspose(128, (3, 3), strides=32, activation=\"relu\", padding=\"same\")(x)\n",
        "  Upsam_Deep2 = layers.Conv2DTranspose(128, (3, 3), strides=16, activation=\"relu\", padding=\"same\")(dec2)\n",
        "  Upsam_Deep3 = layers.Conv2DTranspose(128, (3, 3), strides=8, activation=\"relu\", padding=\"same\")(dec3)\n",
        "  concatted_deep = tf.keras.layers.Concatenate(axis=3)([Upsam_Deep1,Upsam_Deep2,Upsam_Deep3])\n",
        "  result_concatted_deep= layers.Conv2D(1, (1, 1), strides=1, activation=\"relu\", padding=\"same\")(concatted_deep) #224*224*1\n",
        "  #FusionNetwork2\n",
        "  Upsam_Shallow1=layers.Conv2DTranspose(16, (3, 3), strides=4, activation=\"relu\", padding=\"same\")(dec4)\n",
        "  Upsam_Shallow2=layers.Conv2DTranspose(16, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(dec5)\n",
        "  concatted_Shallow = tf.keras.layers.Concatenate()([Upsam_Shallow1,Upsam_Shallow2,dec6])\n",
        "  result_concatted_Shallow= layers.Conv2D(1, (1, 1), strides=1, activation=\"relu\", padding=\"same\",)(concatted_Shallow) #224*224*1\n",
        "  #Concatenate all results\n",
        "  concatted_all = tf.keras.layers.Concatenate()([dec7,result_concatted_deep,result_concatted_Shallow])\n",
        "  final_output= layers.Conv2D(1, (1, 1), strides=1, activation=\"sigmoid\",name=name, padding=\"same\",kernel_regularizer=regularizers.L2(l2=0.005),\n",
        "      bias_regularizer=regularizers.L2(l2=0.0005))(concatted_all) #224*224*1\n",
        "  return final_output"
      ],
      "metadata": {
        "id": "FD5FYDYECkLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "FYKatc_MClde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def googlenet():\n",
        "  layer_in = Input(shape=(224, 224, 3))  \n",
        "  # stage-1\n",
        "  layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
        "  layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "  layer = BatchNormalization()(layer)\n",
        "  # stage-2\n",
        "  layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
        "  layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
        "  layer = BatchNormalization()(layer)\n",
        "  layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "  # stage-3\n",
        "  layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
        "  layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
        "  layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "  # stage-4\n",
        "  layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
        "  ident1  = ident_auxiliary(layer, name='ident1')\n",
        "  #aux1  = auxiliary(layer, name='aux1')\n",
        "  layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
        "  layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
        "  layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
        "  ident2 =ident_auxiliary(layer, name='ident2')\n",
        "  #aux2  = auxiliary(layer, name='aux2')\n",
        "  layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
        "  layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "  # stage-5\n",
        "  layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
        "  layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
        "  ident  = identifier(layer, name='ident')\n",
        "  #layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
        "  # stage-6\n",
        "  #layer = Flatten()(layer)\n",
        "  #layer = Dropout(0.4)(layer)\n",
        "  #layer = Dense(units=256, activation='linear')(layer)\n",
        "  #main = Dense(units=1, activation='sigmoid', name='main')(layer)  \n",
        "  model = Model(inputs=layer_in, outputs=[ident,ident1,ident2]) \n",
        "  return model"
      ],
      "metadata": {
        "id": "YZiuMsc8Cp9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = googlenet()"
      ],
      "metadata": {
        "id": "Flaa3DFKC0U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StopOnPoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, point):\n",
        "        super(StopOnPoint, self).__init__()\n",
        "        self.point = point\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        accuracy = logs[\"ident_accuracy\"]\n",
        "        if accuracy > self.point:\n",
        "            self.model.stop_training = True\n",
        "callbacks = [StopOnPoint(0.98)]"
      ],
      "metadata": {
        "id": "JWTMsGMqC4se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = CHUK_images[:604].astype(np.float32)/ 255.0\n",
        "y_train=CHUK_labels[:604].astype(np.float32)/ 255.0\n",
        "y_train=np.where(y_train>0.5,1.0,0.0)\n",
        "y_train=(y_train)"
      ],
      "metadata": {
        "id": "4rjieB5UDJb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss1=\"binary_crossentropy\"\n",
        "model.compile(keras.optimizers.Adam(learning_rate=1e-3),loss = [loss1,loss1,loss1],metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "BWwkC7GRDOQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,[y_train,y_train,y_train], epochs=120,batch_size=20,validation_split=0.0,shuffle=True,callbacks=[callbacks])\n",
        "model.save('sbdn_googlenet_exp2_chuk-dut_szu_model.h5')"
      ],
      "metadata": {
        "id": "fsaOz3sYDZnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "print(history_dict.keys())"
      ],
      "metadata": {
        "id": "6zgvTnkdDfnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_csv_file = 'sbdn-googlenet_exp2-history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "metadata": {
        "id": "oWP72LgcDvXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"ident_accuracy\"])\n",
        "plt.plot(history.history['ident_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V1RrBlFeD8Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_images=CHUK_images[604:]\n",
        "eval_labels=CHUK_labels[604:]"
      ],
      "metadata": {
        "id": "Jfd5ARITDnEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_labels.shape"
      ],
      "metadata": {
        "id": "xbN3ctpODnrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "images = eval_images\n",
        "model = load_model(\"sbdn_googlenet_exp2_chuk-dut_szu_model.h5\")\n",
        "predictions=[]\n",
        "for i in range(images.shape[0]):\n",
        "  img = images[i]\n",
        "  img = img.astype(np.float32)/ 255.0\n",
        "  img = np.expand_dims(img, -1)\n",
        "  img = np.expand_dims(img, 0)\n",
        "  pred = model.predict(img)\n",
        "  predictions.append(pred)"
      ],
      "metadata": {
        "id": "SKr9_7gsEFvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}